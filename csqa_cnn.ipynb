{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbdoCooder/csqa-cnn/blob/main/csqa_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NG6bWnNy-NsB",
        "outputId": "5468e496-aa81-4cb6-9b12-7ee1d664fc9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.22-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from opendatasets) (4.67.1)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.12/dist-packages (from opendatasets) (1.7.4.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from opendatasets) (8.3.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2026.1.4)\n",
            "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.4.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (3.11)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (5.29.5)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.32.4)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (75.2.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (2.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.12/dist-packages (from kaggle->opendatasets) (0.5.1)\n",
            "Downloading opendatasets-0.1.22-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.22\n"
          ]
        }
      ],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CSet_3eE__ca",
        "outputId": "01136a23-18fd-426e-f4c4-9aff7be7ebc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: abdelkaderabdocooder\n",
            "Your Kaggle Key: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Dataset URL: https://www.kaggle.com/datasets/sriramr/fruits-fresh-and-rotten-for-classification\n",
            "Downloading fruits-fresh-and-rotten-for-classification.zip to ./fruits-fresh-and-rotten-for-classification\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.58G/3.58G [00:58<00:00, 65.4MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/datasets/sriramr/fruits-fresh-and-rotten-for-classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "NYMmXH-zjrTH",
        "outputId": "adf38cbe-cc94-4470-cd6b-c85d2c7de6f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Moving files from freshapples to /content/fruits-fresh-and-rotten-for-classification/dataset/train/Fresh...\n",
            "Moving files from freshoranges to /content/fruits-fresh-and-rotten-for-classification/dataset/train/Fresh...\n",
            "Moving files from freshbanana to /content/fruits-fresh-and-rotten-for-classification/dataset/train/Fresh...\n",
            "Moving files from rottenoranges to /content/fruits-fresh-and-rotten-for-classification/dataset/train/Rotten...\n",
            "Moving files from rottenbanana to /content/fruits-fresh-and-rotten-for-classification/dataset/train/Rotten...\n",
            "Moving files from rottenapples to /content/fruits-fresh-and-rotten-for-classification/dataset/train/Rotten...\n",
            "Reorganization complete!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. Setup the path (same as before)\n",
        "dataset_path = '/content/fruits-fresh-and-rotten-for-classification/dataset/train'\n",
        "\n",
        "# 2. Create the two main categories\n",
        "categories = ['Fresh', 'Rotten']\n",
        "for category in categories:\n",
        "    os.makedirs(os.path.join(dataset_path, category), exist_ok=True)\n",
        "\n",
        "# 3. Loop through the existing folders and move files\n",
        "for folder_name in os.listdir(dataset_path):\n",
        "    folder_path = os.path.join(dataset_path, folder_name)\n",
        "\n",
        "    # Skip if it's not a folder or if it's one of our new target folders\n",
        "    if not os.path.isdir(folder_path) or folder_name in categories:\n",
        "        continue\n",
        "\n",
        "    # Decide where to move the files based on the name\n",
        "    destination = None\n",
        "    if folder_name.lower().startswith('fresh'):\n",
        "        destination = os.path.join(dataset_path, 'Fresh')\n",
        "    elif folder_name.lower().startswith('rotten'):\n",
        "        destination = os.path.join(dataset_path, 'Rotten')\n",
        "\n",
        "    # Move the files if a destination was found\n",
        "    if destination:\n",
        "        print(f\"Moving files from {folder_name} to {destination}...\")\n",
        "        for file_name in os.listdir(folder_path):\n",
        "            src = os.path.join(folder_path, file_name)\n",
        "            dst = os.path.join(destination, file_name)\n",
        "            shutil.move(src, dst)\n",
        "\n",
        "        # Optional: Remove the old empty folder to keep things clean\n",
        "        os.rmdir(folder_path)\n",
        "\n",
        "print(\"Reorganization complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Z5JipucAXku",
        "outputId": "cc893224-f9d3-4fe6-88c1-6de599f7877e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 10901 files belonging to 2 classes.\n",
            "Using 8721 files for training.\n",
            "Found 10901 files belonging to 2 classes.\n",
            "Using 2180 files for validation.\n",
            "Classes found: ['Fresh', 'Rotten']\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# 1. Define the path and parameters\n",
        "train_path = '/content/fruits-fresh-and-rotten-for-classification/dataset/train'\n",
        "batch_size = 32\n",
        "img_height = 224\n",
        "img_width = 224\n",
        "\n",
        "# 2. Load the training data (80% of data)\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory (\n",
        "  train_path,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "# 3. Load the validation data (20% of data)\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_path,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "# 4. Check the class names\n",
        "class_names = train_ds.class_names\n",
        "print(\"Classes found:\", class_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "JzLkIywrLyDF",
        "outputId": "25885534-15dc-4552-e89c-bc901f2c047c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ mobilenetv2_1.00_224            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)     â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)                    â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d_1      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,562</span> â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ],
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ mobilenetv2_1.00_224            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)     â”‚     \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)                    â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooling2d_1      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              â”‚         \u001b[38;5;34m2,562\u001b[0m â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,260,546</span> (8.62 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,260,546\u001b[0m (8.62 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,562</span> (10.01 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,562\u001b[0m (10.01 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# 1. Load the MobileNetV2 base model (without the top layer)\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False\n",
        ")\n",
        "\n",
        "# 2. Freeze the base model (so we don't destroy pre-learned patterns)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Build the final model\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(2, activation='softmax') # 2 neurons for Fresh/Rotten\n",
        "])\n",
        "\n",
        "# 4. Check the structure\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWmlGQ7bjNNL",
        "outputId": "d5aa7f2f-0cce-462a-c764-56c4df473cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model compiled and ready for training!\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "print(\"Model compiled and ready for training!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c1K8HJXj8UN",
        "outputId": "166bc545-feb8-4eb5-c002-8df924693074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m544s\u001b[0m 2s/step - accuracy: 0.7651 - loss: 0.4857 - val_accuracy: 0.8972 - val_loss: 0.2552\n",
            "Epoch 2/5\n",
            "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m565s\u001b[0m 2s/step - accuracy: 0.8832 - loss: 0.2702 - val_accuracy: 0.9128 - val_loss: 0.2177\n",
            "Epoch 3/5\n",
            "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 2s/step - accuracy: 0.9076 - loss: 0.2297 - val_accuracy: 0.9216 - val_loss: 0.2093\n",
            "Epoch 4/5\n",
            "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m594s\u001b[0m 2s/step - accuracy: 0.9167 - loss: 0.2151 - val_accuracy: 0.9220 - val_loss: 0.1959\n",
            "Epoch 5/5\n",
            "\u001b[1m273/273\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 2s/step - accuracy: 0.9191 - loss: 0.2022 - val_accuracy: 0.9275 - val_loss: 0.1886\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "id": "hAmU-GuQwlFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95f72872-fe0a-4250-8873-51b1ad13aece"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STARTING IOT CONVEYOR BELT SIMULATION (10 items) ---\n",
            "\n",
            "[CAM_01] Item #1 Detected...\n",
            "   Analysis: Rotten (74.05%)\n",
            "   Action:   ğŸš¨ REJECTED (ANOMALY)\n",
            "   ğŸ“Š Current Loss Rate: 100.00%\n",
            "\n",
            "[CAM_01] Item #2 Detected...\n",
            "   Analysis: Fresh (93.52%)\n",
            "   Action:   âœ… ACCEPTED\n",
            "   ğŸ“Š Current Loss Rate: 50.00%\n",
            "\n",
            "[CAM_01] Item #3 Detected...\n",
            "   Analysis: Rotten (71.51%)\n",
            "   Action:   ğŸš¨ REJECTED (ANOMALY)\n",
            "   ğŸ“Š Current Loss Rate: 66.67%\n",
            "\n",
            "[CAM_01] Item #4 Detected...\n",
            "   Analysis: Rotten (99.88%)\n",
            "   Action:   ğŸš¨ REJECTED (ANOMALY)\n",
            "   ğŸ“Š Current Loss Rate: 75.00%\n",
            "\n",
            "[CAM_01] Item #5 Detected...\n",
            "   Analysis: Rotten (98.32%)\n",
            "   Action:   ğŸš¨ REJECTED (ANOMALY)\n",
            "   ğŸ“Š Current Loss Rate: 80.00%\n",
            "\n",
            "[CAM_01] Item #6 Detected...\n",
            "   Analysis: Rotten (91.43%)\n",
            "   Action:   ğŸš¨ REJECTED (ANOMALY)\n",
            "   ğŸ“Š Current Loss Rate: 83.33%\n",
            "\n",
            "[CAM_01] Item #7 Detected...\n",
            "   Analysis: Rotten (87.98%)\n",
            "   Action:   ğŸš¨ REJECTED (ANOMALY)\n",
            "   ğŸ“Š Current Loss Rate: 85.71%\n",
            "\n",
            "[CAM_01] Item #8 Detected...\n",
            "   Analysis: Fresh (99.64%)\n",
            "   Action:   âœ… ACCEPTED\n",
            "   ğŸ“Š Current Loss Rate: 75.00%\n",
            "\n",
            "[CAM_01] Item #9 Detected...\n",
            "   Analysis: Rotten (99.90%)\n",
            "   Action:   ğŸš¨ REJECTED (ANOMALY)\n",
            "   ğŸ“Š Current Loss Rate: 77.78%\n",
            "\n",
            "[CAM_01] Item #10 Detected...\n",
            "   Analysis: Fresh (99.29%)\n",
            "   Action:   âœ… ACCEPTED\n",
            "   ğŸ“Š Current Loss Rate: 70.00%\n",
            "\n",
            "==================================================\n",
            "SIMULATION COMPLETE\n",
            "   Total Processed: 10\n",
            "   Fresh:  3\n",
            "   Rotten: 7\n",
            "   Final Loss Rate: 70.00%\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "\"\"\"IoT Conveyor Belt Fruit Classification Simulator.\n",
        "\n",
        "This module simulates an IoT camera system that classifies fruits as fresh or rotten\n",
        "using a Fined-Tuned pre-trained TensorFlow model.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SimulationStats:\n",
        "    \"\"\"Tracks statistics for the fruit classification simulation.\"\"\"\n",
        "\n",
        "    total_fruits:     int = 0\n",
        "    rotten_detected:  int = 0\n",
        "    fresh_detected:   int = 0\n",
        "\n",
        "    @property\n",
        "    def loss_rate(self) -> float:\n",
        "        \"\"\"Calculate the current loss rate as a percentage.\"\"\"\n",
        "        if self. total_fruits == 0:\n",
        "            return 0.0\n",
        "        return (self. rotten_detected / self.total_fruits) * 100\n",
        "\n",
        "    def record(self, is_rotten: bool) -> None:\n",
        "        \"\"\"Record a classification result.\"\"\"\n",
        "        self.total_fruits += 1\n",
        "        if is_rotten:\n",
        "            self. rotten_detected += 1\n",
        "        else:\n",
        "            self.fresh_detected += 1\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class ClassificationResult:\n",
        "    \"\"\"Holds the result of a single fruit classification.\"\"\"\n",
        "\n",
        "    image_path: str\n",
        "    predicted_label: str\n",
        "    confidence: float\n",
        "    is_anomaly: bool\n",
        "\n",
        "    @property\n",
        "    def status(self) -> str:\n",
        "        \"\"\"Return a human-readable status string.\"\"\"\n",
        "        return \"ğŸš¨ REJECTED (ANOMALY)\" if self.is_anomaly else \"âœ… ACCEPTED\"\n",
        "\n",
        "\n",
        "class FruitClassifier:\n",
        "    \"\"\"Handles fruit image classification using a pre-trained model.\"\"\"\n",
        "\n",
        "    CLASS_NAMES = ('Fresh', 'Rotten')\n",
        "    IMAGE_SIZE = (224, 224)\n",
        "\n",
        "    def __init__(self, model:  tf.keras.Model):\n",
        "        self.model = model\n",
        "\n",
        "    def classify(self, image_path: str) -> ClassificationResult:\n",
        "        \"\"\"Classify a single fruit image.\n",
        "\n",
        "        Args:\n",
        "            image_path: Path to the fruit image file.\n",
        "\n",
        "        Returns:\n",
        "            ClassificationResult containing prediction details.\n",
        "        \"\"\"\n",
        "        img_array = self._preprocess_image(image_path)\n",
        "        predictions = self.model. predict(img_array, verbose=0)\n",
        "\n",
        "        predicted_class_index = int(np.argmax(predictions[0]))\n",
        "        predicted_label = self.CLASS_NAMES[predicted_class_index]\n",
        "        confidence = float(100 * np.max(predictions[0]))\n",
        "\n",
        "        return ClassificationResult(\n",
        "            image_path=image_path,\n",
        "            predicted_label=predicted_label,\n",
        "            confidence=confidence,\n",
        "            is_anomaly=(predicted_label == 'Rotten')\n",
        "        )\n",
        "\n",
        "    def _preprocess_image(self, image_path: str) -> np.ndarray:\n",
        "        \"\"\"Load and preprocess an image for model inference.\"\"\"\n",
        "        img = tf.keras.utils.load_img(image_path, target_size=self.IMAGE_SIZE)\n",
        "        img_array = tf.keras.utils.img_to_array(img)\n",
        "        return tf.expand_dims(img_array, 0)\n",
        "\n",
        "\n",
        "class IoTConveyorSimulator:\n",
        "    \"\"\"Simulates an IoT camera system on a conveyor belt.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        classifier: FruitClassifier,\n",
        "        source_folder: str,\n",
        "        processing_delay: float = 1.0,\n",
        "        camera_id: str = \"CAM_01\"\n",
        "    ):\n",
        "        self.classifier = classifier\n",
        "        self.source_folder = Path(source_folder)\n",
        "        self.processing_delay = processing_delay\n",
        "        self.camera_id = camera_id\n",
        "        self.stats = SimulationStats()\n",
        "\n",
        "    def _get_image_files(self) -> list[str]:\n",
        "        \"\"\"Collect all image files from Fresh and Rotten folders.\"\"\"\n",
        "        image_files = []\n",
        "\n",
        "        for category in FruitClassifier.CLASS_NAMES:\n",
        "            category_path = self.source_folder / category\n",
        "            if not category_path.exists():\n",
        "                raise FileNotFoundError(f\"Category folder not found: {category_path}\")\n",
        "\n",
        "            for file_path in category_path.iterdir():\n",
        "                if file_path.suffix.lower() in ('.jpg', '.jpeg', '.png', '.bmp'):\n",
        "                    image_files.append(str(file_path))\n",
        "\n",
        "        if not image_files:\n",
        "            raise ValueError(f\"No image files found in {self.source_folder}\")\n",
        "\n",
        "        return image_files\n",
        "\n",
        "    def _print_result(self, item_number: int, result: ClassificationResult) -> None:\n",
        "        \"\"\"Print classification result to console.\"\"\"\n",
        "        print(f\"\\n[{self.camera_id}] Item #{item_number} Detected...\")\n",
        "        print(f\"   Analysis: {result.predicted_label} ({result.confidence:.2f}%)\")\n",
        "        print(f\"   Action:   {result.status}\")\n",
        "        print(f\"   ğŸ“Š Current Loss Rate: {self.stats.loss_rate:.2f}%\")\n",
        "\n",
        "    def run(self, num_fruits:  int = 10) -> SimulationStats:\n",
        "        \"\"\"Run the conveyor belt simulation.\n",
        "\n",
        "        Args:\n",
        "            num_fruits: Number of fruits to process in this simulation run.\n",
        "\n",
        "        Returns:\n",
        "            SimulationStats containing the results of this run.\n",
        "        \"\"\"\n",
        "        print(f\"--- STARTING IOT CONVEYOR BELT SIMULATION ({num_fruits} items) ---\")\n",
        "\n",
        "        all_files = self._get_image_files()\n",
        "        random.shuffle(all_files)\n",
        "\n",
        "        if num_fruits > len(all_files):\n",
        "            print(f\"Warning:  Requested {num_fruits} items but only {len(all_files)} available.\")\n",
        "            num_fruits = len(all_files)\n",
        "\n",
        "        for i in range(num_fruits):\n",
        "            result = self.classifier.classify(all_files[i])\n",
        "            self. stats.record(result.is_anomaly)\n",
        "            self._print_result(i + 1, result)\n",
        "\n",
        "            if self.processing_delay > 0:\n",
        "                time.sleep(self.processing_delay)\n",
        "\n",
        "        self._print_summary()\n",
        "        return self.stats\n",
        "\n",
        "    def _print_summary(self) -> None:\n",
        "        \"\"\"Print final simulation summary.\"\"\"\n",
        "        print(\"\\n\" + \"=\" * 50)\n",
        "        print(\"SIMULATION COMPLETE\")\n",
        "        print(f\"   Total Processed: {self.stats.total_fruits}\")\n",
        "        print(f\"   Fresh:  {self.stats.fresh_detected}\")\n",
        "        print(f\"   Rotten: {self.stats.rotten_detected}\")\n",
        "        print(f\"   Final Loss Rate: {self.stats. loss_rate:.2f}%\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Run the IoT conveyor belt simulation.\"\"\"\n",
        "    # Configuration\n",
        "    source_folder = '/content/fruits-fresh-and-rotten-for-classification/dataset/train'\n",
        "\n",
        "    # Assumes `model` is already loaded in the environment\n",
        "    # model = tf.keras.models.load_model('path/to/your/model')\n",
        "\n",
        "    classifier = FruitClassifier(model)\n",
        "    simulator = IoTConveyorSimulator(\n",
        "        classifier=classifier,\n",
        "        source_folder=source_folder,\n",
        "        processing_delay=1.0\n",
        "    )\n",
        "\n",
        "    stats = simulator.run()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "khVKXKDnz8Se"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U google-generativeai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-NEskPMJ8ATw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "09674e73-c12e-4592-9723-98851f73ccd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Searching for available models...\n",
            "ğŸ“Š No live stats found, using test data...\n",
            "ğŸ¤– Consulting the AI Quality Manager...\n",
            "   Processing 100 items with 40.00% loss rate...\n",
            "âœ… Report generated successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Quality Control Incident Report - Batch Scan Analysis\n\n**Date:** October 26, 2023\n**Prepared For:** Operations Management, Procurement Department\n**Prepared By:** Quality Assurance Department\n**Reference:** IoT System Data Report - Batch [Insert Batch ID/Reference]\n\n---\n\n## 1. Executive Summary\n\nAn automated IoT scan of a recent fruit batch revealed a significant quality issue, with a **40.00% rejection rate** due to spoilage. This unacceptably high loss rate classifies the incident as **CRITICAL**, indicating a severe deviation from quality standards and posing a substantial operational and financial impact. Immediate investigation and corrective actions are imperative to prevent further losses and maintain product quality.\n\n---\n\n## 2. Severity Assessment\n\n*   **Loss Rate Identified:** 40.00%\n*   **Threshold Comparison:**\n    *   Acceptable: < 5.0%\n    *   Warning: 5.0% - 15.0%\n    *   Critical: > 15.0%\n*   **Severity Level:** **CRITICAL**\n\n**Explanation:** The observed loss rate of 40.00% far exceeds the established \"Critical\" threshold of >15.0%. This indicates a profound breakdown in quality control within the supply chain or handling process, necessitating urgent intervention.\n\n---\n\n## 3. Statistical Analysis\n\nThe IoT system scan provided the following data for the batch:\n\n*   **Total Items Scanned:** 100 units\n*   **Fresh Items:** 60 units\n*   **Rotten Items (Rejections):** 40 units\n*   **Calculated Loss Rate:** 40.00%\n\n**Context:** This means that nearly half (40%) of the fruit in this specific batch was unfit for processing, directly translating to a significant reduction in usable yield and an increase in waste disposal costs. This level of spoilage is unsustainable for efficient plant operations.\n\n---\n\n## 4. Root Cause Analysis (Probable Causes)\n\nBased on the high incidence of rotten items, the following are three probable causes for this critical level of spoilage:\n\n*   **Extended Transport Delays and/or Inadequate Transit Conditions:** The fruit may have experienced prolonged transit times, especially if transportation vehicles lacked proper temperature control, ventilation, or were exposed to excessive heat/humidity. This accelerates ripening and spoilage.\n*   **Improper Storage Conditions at Supplier or Receiving:** Before reaching AgriFresh, the fruit might have been stored under suboptimal conditions at the supplier's facility or immediately upon arrival at our receiving dock. Factors like high ambient temperature, excessive humidity, poor air circulation, or co-storage with ethylene-producing fruits can rapidly degrade quality.\n*   **Harvest Timing and Maturity Level:** The fruit might have been harvested past its optimal ripeness window, meaning it was already over-ripe upon leaving the source. Over-ripe fruit has a significantly shorter shelf-life and is much more susceptible to bruising and spoilage during handling and transport.\n\n---\n\n## 5. Immediate Actions\n\nThe following steps are recommended for immediate implementation:\n\n*   **Quarantine Remaining Material:** Immediately segregate and quarantine any remaining raw material from this specific batch or supplier awaiting processing. Do not proceed with processing until further inspection.\n*   **Enhanced Incoming Inspection:** Implement a heightened, manual inspection protocol for all subsequent incoming batches, particularly from the same supplier, focusing on visual signs of spoilage, firmness, and overall quality.\n*   **Review Receiving Procedures:** Conduct an immediate review of receiving protocols to ensure proper temperature checks, visual inspections, and rapid transfer to appropriate storage are being consistently applied.\n*   **Supplier Communication:** Notify the supplier of the critical quality issue with photographic evidence and request details on their harvest, storage, and transport procedures for this batch.\n\n---\n\n## 6. Preventive Measures (Long-Term Recommendations)\n\nTo prevent recurrence of such incidents, the following long-term measures should be considered:\n\n*   **Supplier Audit and Re-evaluation:** Conduct a comprehensive audit of the involved supplier's facilities, including harvest practices, post-harvest handling, storage conditions, and transportation logistics. Consider alternative suppliers if quality standards cannot be consistently met.\n*   **Supply Chain Optimization:** Work with procurement and logistics to review and optimize transport routes, durations, and conditions. Explore options for refrigerated transport and tighter delivery schedules.\n*   **Stricter Incoming Quality Specifications:** Revise and implement more stringent quality specifications for incoming raw materials, potentially including pre-shipment inspections or mandatory freshness indices.\n*   **Advanced Storage Solutions:** Evaluate and invest in advanced climate-controlled storage solutions at AgriFresh to better manage inventory and extend the shelf-life of raw materials upon arrival.\n\n---\n\n## 7. Next Steps\n\n*   **Cross-Departmental Meeting (EOD Today):** Schedule an urgent meeting with representatives from Operations, Procurement, and Quality Assurance to discuss this report, confirm immediate actions, and assign responsibilities.\n*   **Formal Investigation (Within 24 hours):** Initiate a formal investigation into the specific batch and supplier to gather more detailed information on the root cause.\n*   **Supplier Corrective Action Request (Within 48 hours):** Issue a formal Corrective Action Request (CAR) to the supplier, detailing the issue and requiring their proposed corrective and preventive actions.\n*   **Monitoring and Reporting:** QA will closely monitor all incoming batches for the next two weeks and provide daily updates on quality metrics.\n*   **Review of Preventive Measures (Within 1 week):** Procurement and Operations to present a plan for implementing the recommended preventive measures.\n\n---"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\"\"\"AI-Powered Quality Control Report Generator.\n",
        "\n",
        "This module integrates with Google's Gemini API to generate professional\n",
        "quality control reports based on fruit classification statistics.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "from abc import ABC, abstractmethod\n",
        "from dataclasses import dataclass\n",
        "from enum import Enum\n",
        "from typing import Optional, Protocol\n",
        "from google.colab import userdata\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# For Jupyter/Colab environments\n",
        "try:\n",
        "    from IPython.display import Markdown, display\n",
        "    HAS_IPYTHON = True\n",
        "except ImportError:\n",
        "    HAS_IPYTHON = False\n",
        "\n",
        "\n",
        "class SeverityLevel(Enum):\n",
        "    \"\"\"Classification of quality control severity levels.\"\"\"\n",
        "\n",
        "    ACCEPTABLE = \"acceptable\"\n",
        "    WARNING = \"warning\"\n",
        "    CRITICAL = \"critical\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_loss_rate(cls, loss_rate: float) -> \"SeverityLevel\":\n",
        "        \"\"\"Determine severity level based on loss rate percentage.\"\"\"\n",
        "        if loss_rate < 5:\n",
        "            return cls. ACCEPTABLE\n",
        "        elif loss_rate < 15:\n",
        "            return cls.WARNING\n",
        "        return cls.CRITICAL\n",
        "\n",
        "\n",
        "class StatsProtocol(Protocol):\n",
        "    \"\"\"Protocol defining required statistics interface.\"\"\"\n",
        "\n",
        "    total_fruits: int\n",
        "    fresh_detected: int\n",
        "    rotten_detected: int\n",
        "    loss_rate: float\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class QualityStats:\n",
        "    \"\"\"Quality control statistics container.\"\"\"\n",
        "\n",
        "    total_fruits: int\n",
        "    fresh_detected:  int\n",
        "    rotten_detected:  int\n",
        "\n",
        "    @property\n",
        "    def loss_rate(self) -> float:\n",
        "        \"\"\"Calculate loss rate as a percentage.\"\"\"\n",
        "        if self.total_fruits == 0:\n",
        "            return 0.0\n",
        "        return (self.rotten_detected / self.total_fruits) * 100\n",
        "\n",
        "    @property\n",
        "    def severity(self) -> SeverityLevel:\n",
        "        \"\"\"Get the severity level based on current loss rate.\"\"\"\n",
        "        return SeverityLevel.from_loss_rate(self.loss_rate)\n",
        "\n",
        "def get_working_model():\n",
        "    \"\"\"Dynamically finds a working model from your account.\"\"\"\n",
        "    print(\"ğŸ” Searching for available models...\")\n",
        "    try:\n",
        "        # List all models available to your API key\n",
        "        for m in genai.list_models():\n",
        "            if 'generateContent' in m.supported_generation_methods:\n",
        "                # We prefer Flash or Pro models\n",
        "                if 'flash' in m.name:\n",
        "                    return m.name\n",
        "                if 'pro' in m.name and 'vision' not in m.name:\n",
        "                     return m.name\n",
        "        # Fallback to the first available text model\n",
        "        return 'models/gemini-pro'\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: Could not list models ({e}). Defaulting to gemini-1.5-flash\")\n",
        "        return 'gemini-1.5-flash'\n",
        "\n",
        "@dataclass\n",
        "class ReportConfig:\n",
        "    \"\"\"Configuration for report generation.\"\"\"\n",
        "\n",
        "    facility_name: str = \"Industrial Fruit Sorting Facility\"\n",
        "    acceptable_threshold: float = 5.0\n",
        "    critical_threshold: float = 15.0\n",
        "    model_name: str = get_working_model()\n",
        "    temperature: float = 0.7\n",
        "    max_output_tokens: int = 2048\n",
        "\n",
        "\n",
        "class ReportGenerator(ABC):\n",
        "    \"\"\"Abstract base class for report generators.\"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate(self, stats: StatsProtocol, config: ReportConfig) -> str:\n",
        "        \"\"\"Generate a quality control report.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class GeminiReportGenerator(ReportGenerator):\n",
        "    \"\"\"Generates quality control reports using Google's Gemini API.\"\"\"\n",
        "\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the Gemini report generator.\n",
        "\n",
        "        Args:\n",
        "            api_key: Google API key.  If not provided, will look for\n",
        "                     GOOGLE_API_KEY environment variable.\n",
        "\n",
        "        Raises:\n",
        "            ValueError:  If no API key is provided or found.\n",
        "        \"\"\"\n",
        "        self.api_key = api_key or os.environ.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\n",
        "                \"API key required. Either pass api_key parameter or set \"\n",
        "                \"GOOGLE_API_KEY environment variable.\"\n",
        "            )\n",
        "\n",
        "        genai.configure(api_key=self.api_key)\n",
        "\n",
        "    def _build_prompt(self, stats: StatsProtocol, config: ReportConfig) -> str:\n",
        "        \"\"\"Construct the prompt for the AI model.\"\"\"\n",
        "        severity = SeverityLevel.from_loss_rate(stats.loss_rate)\n",
        "\n",
        "        return f\"\"\"\n",
        "You are the Quality Assurance Manager at {config.facility_name}.\n",
        "An IoT system has just finished scanning a batch of fruit with the following results:\n",
        "\n",
        "--- DATA REPORT ---\n",
        "- Total Items Scanned: {stats.total_fruits}\n",
        "- Fresh Items: {stats.fresh_detected}\n",
        "- Rotten Items (Rejections): {stats.rotten_detected}\n",
        "- LOSS RATE: {stats.loss_rate:.2f}%\n",
        "- SEVERITY LEVEL: {severity.value. upper()}\n",
        "-------------------\n",
        "\n",
        "Thresholds:\n",
        "- Acceptable:  < {config.acceptable_threshold}%\n",
        "- Warning: {config.acceptable_threshold}% - {config.critical_threshold}%\n",
        "- Critical: > {config.critical_threshold}%\n",
        "\n",
        "Please generate a professional \"Quality Control Incident Report\" in Markdown format.\n",
        "The report must include:\n",
        "\n",
        "1. **Executive Summary**: Brief overview of the production run status.\n",
        "2. **Severity Assessment**:  Classification based on the loss rate with explanation.\n",
        "3. **Statistical Analysis**: Breakdown of the numbers with context.\n",
        "4. **Root Cause Analysis**: Three specific probable causes for this level of rot\n",
        "   (e.g., storage humidity, transport delays, harvest timing, supply chain issues).\n",
        "5. **Immediate Actions**: Recommended operational steps to address the issue.\n",
        "6. **Preventive Measures**: Long-term recommendations to prevent recurrence.\n",
        "7. **Next Steps**: Follow-up actions and timeline.\n",
        "\n",
        "Format the report professionally with clear sections and bullet points.\n",
        "\"\"\"\n",
        "\n",
        "    def generate(self, stats: StatsProtocol, config: Optional[ReportConfig] = None) -> str:\n",
        "        \"\"\"Generate a quality control report using Gemini.\n",
        "\n",
        "        Args:\n",
        "            stats: Statistics from the fruit classification simulation.\n",
        "            config: Optional configuration for report generation.\n",
        "\n",
        "        Returns:\n",
        "            Generated report as a Markdown string.\n",
        "\n",
        "        Raises:\n",
        "            ConnectionError: If unable to connect to the Gemini API.\n",
        "            RuntimeError: If the API returns an error response.\n",
        "        \"\"\"\n",
        "        config = config or ReportConfig()\n",
        "\n",
        "        try:\n",
        "            model = genai.GenerativeModel(\n",
        "                model_name=config.model_name,\n",
        "                generation_config={\n",
        "                    \"temperature\": config. temperature,\n",
        "                    \"max_output_tokens\": config.max_output_tokens,\n",
        "                }\n",
        "            )\n",
        "\n",
        "            prompt = self._build_prompt(stats, config)\n",
        "            response = model.generate_content(prompt)\n",
        "\n",
        "            if not response.text:\n",
        "                raise RuntimeError(\"Empty response received from Gemini API\")\n",
        "\n",
        "            return response.text\n",
        "\n",
        "        except genai.types.BlockedPromptException as e:\n",
        "            raise RuntimeError(f\"Prompt was blocked by safety filters: {e}\")\n",
        "        except genai.types.StopCandidateException as e:\n",
        "            raise RuntimeError(f\"Generation stopped unexpectedly: {e}\")\n",
        "        except Exception as e:\n",
        "            raise ConnectionError(f\"Failed to connect to Gemini API: {e}\")\n",
        "\n",
        "\n",
        "class QualityReportManager:\n",
        "    \"\"\"Manages quality report generation and display.\"\"\"\n",
        "\n",
        "    def __init__(self, generator: ReportGenerator):\n",
        "        self.generator = generator\n",
        "        self._last_report:  Optional[str] = None\n",
        "\n",
        "    def create_report(\n",
        "        self,\n",
        "        stats: StatsProtocol,\n",
        "        config: Optional[ReportConfig] = None,\n",
        "        verbose: bool = True\n",
        "    ) -> str:\n",
        "        \"\"\"Create a quality control report.\n",
        "\n",
        "        Args:\n",
        "            stats: Statistics from the fruit classification.\n",
        "            config: Optional report configuration.\n",
        "            verbose: Whether to print progress messages.\n",
        "\n",
        "        Returns:\n",
        "            Generated report as a string.\n",
        "        \"\"\"\n",
        "        if verbose:\n",
        "            print(\"ğŸ¤– Consulting the AI Quality Manager...\")\n",
        "            print(f\"   Processing {stats.total_fruits} items with \"\n",
        "                  f\"{stats.loss_rate:.2f}% loss rate...\")\n",
        "\n",
        "        self._last_report = self.generator.generate(stats, config)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"âœ… Report generated successfully!\")\n",
        "\n",
        "        return self._last_report\n",
        "\n",
        "    def display_report(self, report: Optional[str] = None) -> None:\n",
        "        \"\"\"Display the report in the appropriate format.\n",
        "\n",
        "        Args:\n",
        "            report: Report to display.  Uses last generated report if not provided.\n",
        "        \"\"\"\n",
        "        report = report or self._last_report\n",
        "\n",
        "        if not report:\n",
        "            print(\"No report available.  Generate one first using create_report().\")\n",
        "            return\n",
        "\n",
        "        if HAS_IPYTHON:\n",
        "            display(Markdown(report))\n",
        "        else:\n",
        "            print(report)\n",
        "\n",
        "    def save_report(self, filepath: str, report: Optional[str] = None) -> None:\n",
        "        \"\"\"Save the report to a file.\n",
        "\n",
        "        Args:\n",
        "            filepath: Path to save the report.\n",
        "            report: Report to save.  Uses last generated report if not provided.\n",
        "        \"\"\"\n",
        "        report = report or self._last_report\n",
        "\n",
        "        if not report:\n",
        "            raise ValueError(\"No report available to save.\")\n",
        "\n",
        "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(report)\n",
        "\n",
        "        print(f\"ğŸ“„ Report saved to:  {filepath}\")\n",
        "\n",
        "\n",
        "def create_test_stats(\n",
        "    total:  int = 100,\n",
        "    rotten: int = 40\n",
        ") -> QualityStats:\n",
        "    \"\"\"Create test statistics for demonstration purposes.\"\"\"\n",
        "    return QualityStats(\n",
        "        total_fruits=total,\n",
        "        fresh_detected=total - rotten,\n",
        "        rotten_detected=rotten\n",
        "    )\n",
        "\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "def main():\n",
        "    \"\"\"Run the quality report generation.\"\"\"\n",
        "    # Option 1: Set API key via environment variable (recommended)\n",
        "    # export GOOGLE_API_KEY=\"your-api-key-here\"\n",
        "\n",
        "    # Option 2: Pass API key directly (less secure, avoid in production)\n",
        "    # generator = GeminiReportGenerator(api_key=\"your-api-key-here\")\n",
        "    # This retrieves the secret saved in Collab\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "    # Set it as an environment variable so the Gemini library can find it automatically\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "    try:\n",
        "        generator = GeminiReportGenerator()\n",
        "    except ValueError as e:\n",
        "        print(f\"âš ï¸  Configuration Error: {e}\")\n",
        "        print(\"\\nTo use this module, set your API key:\")\n",
        "        print(\"  Option 1: Set GOOGLE_API_KEY environment variable\")\n",
        "        print(\"  Option 2: Pass api_key to GeminiReportGenerator()\")\n",
        "        return\n",
        "\n",
        "    manager = QualityReportManager(generator)\n",
        "\n",
        "    # Use existing stats if available, otherwise create test data\n",
        "    # This allows seamless integration with the IoT simulator\n",
        "    if 'stats' in globals():\n",
        "        quality_stats = stats  # type: ignore\n",
        "        print(\"ğŸ“Š Using live statistics from simulation...\")\n",
        "    else:\n",
        "        print(\"ğŸ“Š No live stats found, using test data...\")\n",
        "        quality_stats = create_test_stats(total=100, rotten=40)\n",
        "\n",
        "    # Configure and generate report\n",
        "    config = ReportConfig(\n",
        "        facility_name=\"AgriFresh Processing Plant\",\n",
        "        acceptable_threshold=5.0,\n",
        "        critical_threshold=15.0\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        report = manager.create_report(quality_stats, config)\n",
        "        manager.display_report()\n",
        "\n",
        "        # Optionally save the report\n",
        "        # manager.save_report(\"quality_report.md\")\n",
        "\n",
        "    except (ConnectionError, RuntimeError) as e:\n",
        "        print(f\"âŒ Error generating report: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1wM8EVTpln9xglxmNNJnVqTlQ08bnRNog",
      "authorship_tag": "ABX9TyMaKrVr8otbTpl4v+8pXp0N",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}